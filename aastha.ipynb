{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99651375-935e-4f59-ae01-2f3277caa5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/15 | Best Fitness: 0.761781530918006\n",
      "Iteration 2/15 | Best Fitness: 0.761781530918006\n",
      "Iteration 3/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 4/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 5/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 6/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 7/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 8/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 9/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 10/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 11/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 12/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 13/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 14/15 | Best Fitness: 0.7722691364750749\n",
      "Iteration 15/15 | Best Fitness: 0.7722691364750749\n",
      "\n",
      "Best MOA Accuracy: 0.7722691364750749\n",
      "Selected Feature Count: 66\n",
      "Selected Feature Indexes: [ 0  2  3  4  5  9 10 11 12 13 14 16 18 19 20 21 23 24 25 26 27 28 30 31\n",
      " 32 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n",
      " 58 59 60 62 63 64 65 66 67 69 70 72 73 74 75 76 77 78]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset/All.csv\")\n",
    "\n",
    "# Replace inf and -inf with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"URL_Type_obf_Type\"])\n",
    "df = df.drop(columns=[\"URL_Type_obf_Type\"])\n",
    "\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# ----------------------------------------\n",
    "# MOA Fitness Function\n",
    "# ----------------------------------------\n",
    "def fitness_function(feature_mask):\n",
    "    selected_features = np.where(feature_mask == 1)[0]\n",
    "    \n",
    "    if len(selected_features) == 0:\n",
    "        return 0\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_selected, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = AdaBoostClassifier(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Mayfly Optimization Algorithm (MOA)\n",
    "# ----------------------------------------\n",
    "def MOA(num_mayflies=8, max_iter=15, num_features=X.shape[1]):\n",
    "    population = np.random.randint(0, 2, (num_mayflies, num_features))\n",
    "    best_solution = population[0].copy()\n",
    "    best_fitness = fitness_function(best_solution)\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        for i in range(num_mayflies):\n",
    "            r = np.random.rand()\n",
    "            step = np.random.randint(0, 2, num_features)\n",
    "\n",
    "            if r < 0.5:\n",
    "                population[i] = np.logical_xor(population[i], step).astype(int)\n",
    "            else:\n",
    "                population[i] = np.logical_or(population[i], best_solution).astype(int)\n",
    "\n",
    "            current_fitness = fitness_function(population[i])\n",
    "\n",
    "            if current_fitness > best_fitness:\n",
    "                best_fitness = current_fitness\n",
    "                best_solution = population[i].copy()\n",
    "\n",
    "        print(f\"Iteration {it+1}/{max_iter} | Best Fitness: {best_fitness}\")\n",
    "\n",
    "    return best_solution, best_fitness\n",
    "\n",
    "# Run MOA\n",
    "best_features, best_accuracy = MOA()\n",
    "\n",
    "print(\"\\nBest MOA Accuracy:\", best_accuracy)\n",
    "print(\"Selected Feature Count:\", best_features.sum())\n",
    "print(\"Selected Feature Indexes:\", np.where(best_features == 1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981207e0-2977-48bc-96b8-c7bf172d1d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature count: 66\n",
      "Max index: 78\n",
      "Total features: 79\n",
      "=== AdaBoost (MOA Selected Features - Baseline) ===\n",
      "Accuracy: 0.7722691364750749\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1306   37   49  158   78]\n",
      " [  48 1297   77   89   15]\n",
      " [ 107  258  799  148   20]\n",
      " [  99   75  148 1140   35]\n",
      " [ 123    7   25   76 1128]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1628\n",
      "           1       0.77      0.85      0.81      1526\n",
      "           2       0.73      0.60      0.66      1332\n",
      "           3       0.71      0.76      0.73      1497\n",
      "           4       0.88      0.83      0.86      1359\n",
      "\n",
      "    accuracy                           0.77      7342\n",
      "   macro avg       0.77      0.77      0.77      7342\n",
      "weighted avg       0.77      0.77      0.77      7342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Rebuild FULL dataset again\n",
    "df = pd.read_csv(\"dataset/All.csv\")\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"URL_Type_obf_Type\"])\n",
    "df = df.drop(columns=[\"URL_Type_obf_Type\"])\n",
    "\n",
    "X_full = df.drop(columns=[\"label\"]).values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Convert MOA mask → indexes\n",
    "selected_indexes = np.where(best_features == 1)[0]\n",
    "\n",
    "print(\"Selected feature count:\", len(selected_indexes))\n",
    "print(\"Max index:\", selected_indexes.max())\n",
    "print(\"Total features:\", X_full.shape[1])\n",
    "\n",
    "# Apply feature selection correctly\n",
    "X_selected = X_full[:, selected_indexes]\n",
    "\n",
    "# Train-test split (80–20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train AdaBoost baseline\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, preds)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "cr = classification_report(y_test, preds)\n",
    "\n",
    "print(\"=== AdaBoost (MOA Selected Features - Baseline) ===\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1a08e4-93b0-4fd4-a419-b1bc1d69eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/15 | Best Fitness: 0.7877962408063198\n",
      "Iteration 2/15 | Best Fitness: 0.7931081449196404\n",
      "Iteration 3/15 | Best Fitness: 0.7931081449196404\n",
      "Iteration 4/15 | Best Fitness: 0.7931081449196404\n",
      "Iteration 5/15 | Best Fitness: 0.7973304276763824\n",
      "Iteration 6/15 | Best Fitness: 0.7973304276763824\n",
      "Iteration 7/15 | Best Fitness: 0.7973304276763824\n",
      "Iteration 8/15 | Best Fitness: 0.7973304276763824\n",
      "Iteration 9/15 | Best Fitness: 0.7973304276763824\n",
      "Iteration 10/15 | Best Fitness: 0.7973304276763824\n",
      "Iteration 11/15 | Best Fitness: 0.7973304276763824\n",
      "Iteration 12/15 | Best Fitness: 0.800463089076546\n",
      "Iteration 13/15 | Best Fitness: 0.800463089076546\n",
      "Iteration 14/15 | Best Fitness: 0.8023699264505584\n",
      "Iteration 15/15 | Best Fitness: 0.8023699264505584\n",
      "\n",
      "Best BAT Parameters:\n",
      "n_estimators: 290\n",
      "learning_rate: 0.8896174277790695\n",
      "Best BAT Accuracy: 0.8023699264505584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use the same X_selected, y from previous step\n",
    "\n",
    "# ---------------------------\n",
    "# Fitness Function for BAT\n",
    "# ---------------------------\n",
    "def bat_fitness(params):\n",
    "    n_estimators = int(params[0])\n",
    "    learning_rate = float(params[1])\n",
    "\n",
    "    model = AdaBoostClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_selected, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "# ---------------------------\n",
    "# BAT Algorithm\n",
    "# ---------------------------\n",
    "def BAT(pop_size=8, max_iter=15):\n",
    "    # Bounds: [n_estimators, learning_rate]\n",
    "    bounds = np.array([\n",
    "        [50, 300],     # n_estimators\n",
    "        [0.01, 1.0]    # learning_rate\n",
    "    ])\n",
    "\n",
    "    dim = bounds.shape[0]\n",
    "    \n",
    "    # Initialize population\n",
    "    population = np.random.uniform(bounds[:,0], bounds[:,1], (pop_size, dim))\n",
    "    \n",
    "    fitness_vals = np.array([bat_fitness(ind) for ind in population])\n",
    "\n",
    "    best_idx = np.argmax(fitness_vals)\n",
    "    best_solution = population[best_idx].copy()\n",
    "    best_fitness = fitness_vals[best_idx]\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        for i in range(pop_size):\n",
    "            # Random walk\n",
    "            eps = np.random.uniform(-1, 1, dim)\n",
    "            new_solution = population[i] + eps * (best_solution - population[i])\n",
    "            new_solution = np.clip(new_solution, bounds[:,0], bounds[:,1])\n",
    "\n",
    "            new_fitness = bat_fitness(new_solution)\n",
    "\n",
    "            if new_fitness > fitness_vals[i]:\n",
    "                population[i] = new_solution\n",
    "                fitness_vals[i] = new_fitness\n",
    "\n",
    "                if new_fitness > best_fitness:\n",
    "                    best_fitness = new_fitness\n",
    "                    best_solution = new_solution.copy()\n",
    "\n",
    "        print(f\"Iteration {it+1}/{max_iter} | Best Fitness: {best_fitness}\")\n",
    "\n",
    "    return best_solution, best_fitness\n",
    "\n",
    "# Run BAT\n",
    "best_params, best_bat_acc = BAT()\n",
    "\n",
    "print(\"\\nBest BAT Parameters:\")\n",
    "print(\"n_estimators:\", int(best_params[0]))\n",
    "print(\"learning_rate:\", best_params[1])\n",
    "print(\"Best BAT Accuracy:\", best_bat_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b19f8a-8512-4786-8318-ed8431a3274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AdaBoost (MOA + BAT Optimized) ===\n",
      "Accuracy: 0.7823481340234268\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1306   41   52  142   87]\n",
      " [  12 1299  149   50   16]\n",
      " [  74  248  813  130   67]\n",
      " [  82   63  161 1147   44]\n",
      " [  84   13   17   66 1179]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1628\n",
      "           1       0.78      0.85      0.81      1526\n",
      "           2       0.68      0.61      0.64      1332\n",
      "           3       0.75      0.77      0.76      1497\n",
      "           4       0.85      0.87      0.86      1359\n",
      "\n",
      "    accuracy                           0.78      7342\n",
      "   macro avg       0.78      0.78      0.78      7342\n",
      "weighted avg       0.78      0.78      0.78      7342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Train AdaBoost with BAT-optimized parameters\n",
    "optimized_model = AdaBoostClassifier(\n",
    "    n_estimators=178,\n",
    "    learning_rate=0.7574395794737445,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "optimized_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "opt_preds = optimized_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "opt_acc = accuracy_score(y_test, opt_preds)\n",
    "opt_cm = confusion_matrix(y_test, opt_preds)\n",
    "opt_cr = classification_report(y_test, opt_preds)\n",
    "\n",
    "print(\"=== AdaBoost (MOA + BAT Optimized) ===\")\n",
    "print(\"Accuracy:\", opt_acc)\n",
    "print(\"\\nConfusion Matrix:\\n\", opt_cm)\n",
    "print(\"\\nClassification Report:\\n\", opt_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ba464-8942-4572-9dbb-1fb4a5bcdec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
